{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Collect & Import all the libraries once before coding","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport random \nfrom sklearn.model_selection import train_test_split\nimport shutil\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom keras import models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:30.529772Z","iopub.execute_input":"2022-05-15T18:45:30.530110Z","iopub.status.idle":"2022-05-15T18:45:36.794492Z","shell.execute_reply.started":"2022-05-15T18:45:30.530075Z","shell.execute_reply":"2022-05-15T18:45:36.793763Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## EDA och filhantering ","metadata":{}},{"cell_type":"markdown","source":"#### Läs in 10 bilder slumpmässigt, plotta dem och extrahera deras labels och skriv ut i titeln.\n","metadata":{}},{"cell_type":"code","source":"def plot_n_random_img(n, path):\n\n    # Seclect sample images\n    samples = random.sample(os.listdir(path), n)\n\n    # loop the path for images\n    path_images = [f\"{path}/{file_name}\" for file_name in samples]\n\n    # read the images to array\n    images_read = [plt.imread(file) for file in path_images]\n\n    # Display the images with labels\n    fig, axes = plt.subplots(2, int(n/2), figsize=(15, 6))\n    for i, ax in enumerate(axes.flatten()):\n        ax.imshow(images_read[i])\n        ax.set_title(f\"{samples[i]}\")\n        ax.axis(\"off\")\n    \n    plt.suptitle(f\"{n} random images from cats and dogs\")\n\n\npath = \"../input/dogs-vs-cats/train/train\"\nplot_n_random_img(10, path)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:36.797343Z","iopub.execute_input":"2022-05-15T18:45:36.797808Z","iopub.status.idle":"2022-05-15T18:45:38.774113Z","shell.execute_reply.started":"2022-05-15T18:45:36.797767Z","shell.execute_reply":"2022-05-15T18:45:38.773403Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#### Skapa folderstrukturen nedan med Python:","metadata":{}},{"cell_type":"markdown","source":"Create the dir (train/val/test) for small data:","metadata":{}},{"cell_type":"code","source":"experiment_small_data = \"experiment_small_data\"\nos.mkdir(experiment_small_data)\n\n# For small train\n\nsmall_train_dir = os.path.join(experiment_small_data, \"train\")\nos.mkdir(small_train_dir)\n\n# For small test\n\nsmall_test_dir = os.path.join(experiment_small_data, \"test\")\nos.mkdir(small_test_dir)\n\n# For small val \n\nsmall_val_dir = os.path.join(experiment_small_data, \"val\")\nos.mkdir(small_val_dir)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:38.775062Z","iopub.execute_input":"2022-05-15T18:45:38.775285Z","iopub.status.idle":"2022-05-15T18:45:38.782728Z","shell.execute_reply.started":"2022-05-15T18:45:38.775255Z","shell.execute_reply":"2022-05-15T18:45:38.781903Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Create the dir (train/test) for tiny data:","metadata":{}},{"cell_type":"code","source":"experiment_tiny_data = 'experiment_tiny_data'\nos.mkdir(experiment_tiny_data)\n\n# For tiny train\n\ntiny_train_dir = os.path.join(experiment_tiny_data, \"train\")\nos.mkdir(tiny_train_dir)\n\n# For tiny test\n\ntiny_test_dir = os.path.join(experiment_tiny_data, \"test\")\nos.mkdir(tiny_test_dir)\n\n# For tiny val \n\ntiny_val_dir = os.path.join(experiment_tiny_data, \"val\")\nos.mkdir(tiny_val_dir)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:38.784327Z","iopub.execute_input":"2022-05-15T18:45:38.784966Z","iopub.status.idle":"2022-05-15T18:45:38.792709Z","shell.execute_reply.started":"2022-05-15T18:45:38.784912Z","shell.execute_reply":"2022-05-15T18:45:38.791962Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#### Nu ska göra train|val|test split med följande splits:\n\nexperiment_small:\n- train - 1600 (800 dogs, 800 cats)\n- val - 400 (200 dogs, 200 cats)\n- test - 500 (250 dogs, 250 cats)\n\nexperiment_tiny (BONUS):\n- train - 160 (80 dogs, 80 cats)\n- val - 40 (20 dogs, 20 cats)\n- test - 50 (25 dogs, 25 cats)\n\n","metadata":{}},{"cell_type":"code","source":"# Check how many train pics\ntrain_img = os.listdir(\"../input/dogs-vs-cats/train/train\")\nlen(train_img)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:38.795683Z","iopub.execute_input":"2022-05-15T18:45:38.796242Z","iopub.status.idle":"2022-05-15T18:45:38.815464Z","shell.execute_reply.started":"2022-05-15T18:45:38.796204Z","shell.execute_reply":"2022-05-15T18:45:38.814746Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Create a total name's pool for dogs and cats","metadata":{}},{"cell_type":"code","source":"train_cats = [\"cat.{}.jpg\".format(i) for i in random.sample(range(0, 12500), 12500)]\ntrain_dogs = [\"dog.{}.jpg\".format(i) for i in random.sample(range(0, 12500), 12500)]","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:38.816548Z","iopub.execute_input":"2022-05-15T18:45:38.816778Z","iopub.status.idle":"2022-05-15T18:45:38.855784Z","shell.execute_reply.started":"2022-05-15T18:45:38.816746Z","shell.execute_reply":"2022-05-15T18:45:38.855193Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Original folder for img","metadata":{}},{"cell_type":"code","source":"original_dir = \"../input/dogs-vs-cats/train/train\"","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:38.857151Z","iopub.execute_input":"2022-05-15T18:45:38.857420Z","iopub.status.idle":"2022-05-15T18:45:38.861537Z","shell.execute_reply.started":"2022-05-15T18:45:38.857385Z","shell.execute_reply":"2022-05-15T18:45:38.860562Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Define a function for split","metadata":{}},{"cell_type":"code","source":"def train_val_test_split(n_train, n_val, n_test, path_train, path_val, path_test):\n\n    # here randomly select n images from 1st-8000st, 8000st-10000st, 10000st-12500st for train, val and test. \n    # The purpose of this method is to select samples segmently and to avoid data leaking\n\n    train_cat = random.sample(train_cats[0:8000], int(n_train/2))\n    train_dog = random.sample(train_dogs[0:8000], int(n_train/2))\n\n    val_cat = random.sample(train_cats[8000:10000], int(n_val/2))\n    val_dog = random.sample(train_dogs[8000:10000], int(n_val/2))\n\n    test_cat = random.sample(train_cats[10000:12500], int(n_test/2))\n    test_dog = random.sample(train_dogs[10000:12500], int(n_test/2))\n\n    for cats, dogs in zip(train_cat, train_dog):\n        src = os.path.join(original_dir, cats)\n        dst = os.path.join(path_train, cats)\n        shutil.copyfile(src, dst)\n        src = os.path.join(original_dir, dogs)\n        dst = os.path.join(path_train, dogs)\n        shutil.copyfile(src, dst)\n            \n    for cats, dogs in zip(val_cat, val_dog):\n        src = os.path.join(original_dir, cats)\n        dst = os.path.join(path_val, cats)\n        shutil.copyfile(src, dst)\n        src = os.path.join(original_dir, dogs)\n        dst = os.path.join(path_val, dogs)\n        shutil.copyfile(src, dst)\n\n    for cats, dogs in zip(test_cat, test_dog):\n        src = os.path.join(original_dir, cats)\n        dst = os.path.join(path_test, cats)\n        shutil.copyfile(src, dst)\n        src = os.path.join(original_dir, dogs)\n        dst = os.path.join(path_test, dogs)\n        shutil.copyfile(src, dst)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:38.863034Z","iopub.execute_input":"2022-05-15T18:45:38.863352Z","iopub.status.idle":"2022-05-15T18:45:38.878543Z","shell.execute_reply.started":"2022-05-15T18:45:38.863316Z","shell.execute_reply":"2022-05-15T18:45:38.877703Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"For small data:","metadata":{}},{"cell_type":"code","source":"small_train_dir =\"./experiment_small_data/train\"\nsmall_val_dir =\"./experiment_small_data/val\"\nsmall_test_dir =\"./experiment_small_data/test\"\n\ntrain_val_test_split(1600, 400 ,500, small_train_dir, small_val_dir, small_test_dir)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:38.880113Z","iopub.execute_input":"2022-05-15T18:45:38.880364Z","iopub.status.idle":"2022-05-15T18:45:59.748973Z","shell.execute_reply.started":"2022-05-15T18:45:38.880331Z","shell.execute_reply":"2022-05-15T18:45:59.748111Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_small = os.listdir(\"./experiment_small_data/train\")\nval_small = os.listdir(\"./experiment_small_data/val\")\ntest_small = os.listdir(\"./experiment_small_data/test\")\n\n\nlen(train_small), len(val_small), len(test_small)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:59.750268Z","iopub.execute_input":"2022-05-15T18:45:59.750543Z","iopub.status.idle":"2022-05-15T18:45:59.760401Z","shell.execute_reply.started":"2022-05-15T18:45:59.750505Z","shell.execute_reply":"2022-05-15T18:45:59.759457Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"For tiny data:","metadata":{}},{"cell_type":"code","source":"tiny_train_dir =\"./experiment_tiny_data/train\"\ntiny_val_dir =\"./experiment_tiny_data/val\"\ntiny_test_dir =\"./experiment_tiny_data/test\"\n\ntrain_val_test_split(160, 40 ,50, tiny_train_dir, tiny_val_dir, tiny_test_dir)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:45:59.762051Z","iopub.execute_input":"2022-05-15T18:45:59.762368Z","iopub.status.idle":"2022-05-15T18:46:01.853447Z","shell.execute_reply.started":"2022-05-15T18:45:59.762329Z","shell.execute_reply":"2022-05-15T18:46:01.852693Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_tiny = os.listdir(\"./experiment_tiny_data/train\")\nval_tiny = os.listdir(\"./experiment_tiny_data/val\")\ntest_tiny = os.listdir(\"./experiment_tiny_data/test\")\n\n\nlen(train_tiny), len(val_tiny), len(test_tiny)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:01.854595Z","iopub.execute_input":"2022-05-15T18:46:01.854866Z","iopub.status.idle":"2022-05-15T18:46:01.864624Z","shell.execute_reply.started":"2022-05-15T18:46:01.854810Z","shell.execute_reply":"2022-05-15T18:46:01.863789Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### Läs in dataseten från experiment_small, experiment_tiny och plocka ut labelsvektorer, som ska vara one-hot encoded med 0 och 1.\n\n- plotta några bilder med deras respektive labels och kontrollera att det är korrekt.\n- skapa lämplig plot för att kontrollera att dataseten är balanserade\n- skapa lämplig plot för att kontrollera att dataseten är slumpade (dvs inte ex [0, 0, ... 0, 1, 1, ..., 1]).","metadata":{}},{"cell_type":"markdown","source":"Firstly create one-hot labels and randomize the data with function to avoid 0,0,0...1,1,1...","metadata":{}},{"cell_type":"code","source":"def randomize_and_one_hot(path):\n\n    list = os.listdir(path)\n    \n    # shuffle the file names, mix the cat and dog images\n    random.shuffle(list)\n\n    images = [f\"{path}/{file_name}\" for file_name in list]\n\n    y = []\n    X = []\n    \n    for name in images:\n      if \"cat\" in name:\n        y.append(0)\n      elif \"dog\" in name:\n        y.append(1)\n        \n      X.append(cv2.imread(name))\n  \n    return X, y\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:01.866279Z","iopub.execute_input":"2022-05-15T18:46:01.866568Z","iopub.status.idle":"2022-05-15T18:46:01.873423Z","shell.execute_reply.started":"2022-05-15T18:46:01.866519Z","shell.execute_reply":"2022-05-15T18:46:01.872550Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Apply the function to small and tiny files","metadata":{}},{"cell_type":"code","source":"small_train_dir =\"./experiment_small_data/train\"\nsmall_val_dir =\"./experiment_small_data/val\"\nsmall_test_dir =\"./experiment_small_data/test\"\n\nX_train_small, y_train_small = randomize_and_one_hot(small_train_dir)\nX_val_small, y_val_small = randomize_and_one_hot(small_val_dir)\nX_test_small, y_test_small = randomize_and_one_hot(small_test_dir)\n\ntiny_train_dir =\"./experiment_tiny_data/train\"\ntiny_val_dir =\"./experiment_tiny_data/val\"\ntiny_test_dir =\"./experiment_tiny_data/test\"\n\nX_train_tiny, y_train_tiny = randomize_and_one_hot(tiny_train_dir)\nX_val_tiny, y_val_tiny = randomize_and_one_hot(tiny_val_dir)\nX_test_tiny, y_test_tiny = randomize_and_one_hot(tiny_test_dir)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:01.878076Z","iopub.execute_input":"2022-05-15T18:46:01.878367Z","iopub.status.idle":"2022-05-15T18:46:07.635632Z","shell.execute_reply.started":"2022-05-15T18:46:01.878336Z","shell.execute_reply":"2022-05-15T18:46:07.634865Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Plot the images (check)","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 5, figsize=(15, 6))\nfor i, ax in enumerate(axes.flatten()):\n    ax.imshow(X_train_tiny[i])\n    ax.set_title(f\"{y_train_tiny[i]}\")\n    ax.axis(\"off\")\nplt.suptitle(\"10 cats and dogs images with 0/1 labels\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:07.637096Z","iopub.execute_input":"2022-05-15T18:46:07.637506Z","iopub.status.idle":"2022-05-15T18:46:08.321530Z","shell.execute_reply.started":"2022-05-15T18:46:07.637469Z","shell.execute_reply":"2022-05-15T18:46:08.320852Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Plot the balance of the datas","metadata":{}},{"cell_type":"code","source":"datas = [y_train_small, y_val_small, y_test_small, y_train_tiny, y_val_tiny, y_test_tiny]\ntitles = [\"Balance small train\", \"Balance small val\", \n          \"Balance small test\", \"Balance tiny train\", \n         \"Balance tiny val\",\"Balance tiny test\",]\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))\n\nfor ax, data, title in zip(axes.flatten(), datas, titles):\n    sns.countplot(x=data, ax=ax)\n    ax.set(title = title)\n    ax.axis(\"on\")\nplt.suptitle(\"Number of Cats & dogs\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:08.322606Z","iopub.execute_input":"2022-05-15T18:46:08.323162Z","iopub.status.idle":"2022-05-15T18:46:09.138890Z","shell.execute_reply.started":"2022-05-15T18:46:08.323119Z","shell.execute_reply":"2022-05-15T18:46:09.138227Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"From above we can see the same number of dog and cat in different data groups","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n\nfor ax, data, title in zip(axes.flatten(), datas, titles):\n    sns.scatterplot(data=data,linewidth=.2, ax=ax)\n    ax.set(title = title)\n    ax.axis(\"on\")\nplt.suptitle(\"Images distribution\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:09.140181Z","iopub.execute_input":"2022-05-15T18:46:09.140593Z","iopub.status.idle":"2022-05-15T18:46:10.036612Z","shell.execute_reply.started":"2022-05-15T18:46:09.140555Z","shell.execute_reply":"2022-05-15T18:46:10.035737Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Here above the figure shows the dog and cat images are randomly distributed","metadata":{}},{"cell_type":"markdown","source":"# Bildbehandling","metadata":{}},{"cell_type":"markdown","source":"#### a) Skapa en plot för att visualisera bildstorlekarna i träningsdatan. Använd seaborns jointplot.","metadata":{}},{"cell_type":"code","source":"X_train_small[0].shape\n# This is a image with 456*499(size) pixers","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:10.038061Z","iopub.execute_input":"2022-05-15T18:46:10.038331Z","iopub.status.idle":"2022-05-15T18:46:10.045553Z","shell.execute_reply.started":"2022-05-15T18:46:10.038294Z","shell.execute_reply":"2022-05-15T18:46:10.044660Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"For small dataset","metadata":{}},{"cell_type":"code","source":"width_small = [X_train_small[i].shape[0] for i in range(len(X_train_small))]\nlength_small = [X_train_small[i].shape[1] for i in range(len(X_train_small))]\n\nfig = sns.jointplot(x = width_small, y = length_small, xlim = 550, ylim = 550)\nfig.set_axis_labels(\"Width\", \"Length\")\nplt.suptitle(\"JointPlot for small train data\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:10.046797Z","iopub.execute_input":"2022-05-15T18:46:10.047094Z","iopub.status.idle":"2022-05-15T18:46:10.600475Z","shell.execute_reply.started":"2022-05-15T18:46:10.047039Z","shell.execute_reply":"2022-05-15T18:46:10.599819Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"For tiny dataset","metadata":{}},{"cell_type":"code","source":"width_tiny = [X_train_tiny[i].shape[0] for i in range(len(X_train_tiny))]\nlength_tiny = [X_train_tiny[i].shape[1] for i in range(len(X_train_tiny))]\n\nfig = sns.jointplot(x = width_tiny, y = length_tiny, xlim = 550, ylim = 550)\nfig.set_axis_labels(\"Width\", \"Length\")\nplt.suptitle(\"JointPlot for tiny train data\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:10.602102Z","iopub.execute_input":"2022-05-15T18:46:10.602565Z","iopub.status.idle":"2022-05-15T18:46:11.076463Z","shell.execute_reply.started":"2022-05-15T18:46:10.602528Z","shell.execute_reply":"2022-05-15T18:46:11.075698Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"#### b) Välj en lämplig bildstorlek att ändra samtliga bilder till. Gör en analys och fundera på om du behöver slänga bilder. Hur kommer du fram till ditt val?","metadata":{}},{"cell_type":"markdown","source":"The images will have to be reshaped to modeling so that all images have the same shape. This is often a small square image. The image size defaults to keras is (256, 256) and we can use this setting in our case. Because cats/dogs images has a maximal size in 500 (width/length) and 256*256 can retain most of the information. (Maybe change to a smaller size if it running too slow)","metadata":{}},{"cell_type":"markdown","source":"Through the figure analysis of c), we can see that the image size in small/tiny are basically between 100 and 500. This means that the images basically retains the information we need. However, when we browse the images in folder with eyes, can also found very few images that are neither cats nor dogs (t.ex cat.5418). This may affect the accuracy. But due to the small number and the high workload of manual culling, I decided not to act.","metadata":{}},{"cell_type":"markdown","source":"#### c) Gör resize sådant att samtliga bilder är samma storlek och spara dem i numpy arrays med följande struktur:\n<span style=\"color:grey\">(samples, row, cols, color_channels)</span>.  \n","metadata":{}},{"cell_type":"code","source":"def resize(dataset):\n\n\timages_resized = []\n\t\n\tfor data in dataset:\n\t\t\n\t\tresized = cv2.resize(data, (256, 256))\n\t\timages_resized.append(resized)\n\t\t\n\timages_resized = np.asarray(images_resized)\n\t\n\treturn images_resized\n","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:11.077872Z","iopub.execute_input":"2022-05-15T18:46:11.078127Z","iopub.status.idle":"2022-05-15T18:46:11.083354Z","shell.execute_reply.started":"2022-05-15T18:46:11.078092Z","shell.execute_reply":"2022-05-15T18:46:11.082504Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"X_train_small_resized = resize(X_train_small)\nX_val_small_resized = resize(X_val_small)\nX_test_small_resized = resize(X_test_small)\n\nX_train_tiny_resized = resize(X_train_tiny)\nX_val_tiny_resized = resize(X_val_tiny)\nX_test_tiny_resized = resize(X_test_tiny)\n\nX_train_small_resized.shape, X_train_tiny_resized.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:11.085025Z","iopub.execute_input":"2022-05-15T18:46:11.085314Z","iopub.status.idle":"2022-05-15T18:46:12.188003Z","shell.execute_reply.started":"2022-05-15T18:46:11.085274Z","shell.execute_reply":"2022-05-15T18:46:12.187293Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"#### Visualisera därefter ett par styckena bilder.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 4, figsize=(15, 6))\nfor i, ax in enumerate(axes.flatten()):\n    ax.imshow(X_train_small_resized[i])\n    ax.axis(\"on\")\nplt.suptitle(\"Resized images\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:12.189454Z","iopub.execute_input":"2022-05-15T18:46:12.189934Z","iopub.status.idle":"2022-05-15T18:46:12.805329Z","shell.execute_reply.started":"2022-05-15T18:46:12.189895Z","shell.execute_reply":"2022-05-15T18:46:12.804678Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"#### d) Augmentera datan. Varför behövs dataaugmentering och hur beslutar vilka parametrar du valt för augmenteringen?\n","metadata":{}},{"cell_type":"markdown","source":"- When the amount of data is insufficient, the model is easy to overfit, and the accuracy can not improve. Therefore, data augmentation is needed. By using augmentation, it can automatically enhance training data.","metadata":{}},{"cell_type":"markdown","source":"- Here I decided to adjust the following three parameters:\n\n(1) Color.  t.ex. \"featurewise_center\"\n\n(2) Geometry.  t.ex. \"shear_range\"\n\n(3) Bounding box.  t.ex. \"width_shift_range\"","metadata":{}},{"cell_type":"code","source":"scaled_X_train_small_resized = X_train_small_resized.astype(\"float32\") / 255\nscaled_X_val_small_resized = X_val_small_resized.astype(\"float32\") / 255\nscaled_X_test_small_resized = X_test_small_resized.astype(\"float32\") / 255\n\nscaled_X_train_tiny_resized = X_train_tiny_resized.astype(\"float32\") / 255\nscaled_X_val_tiny_resized = X_val_tiny_resized.astype(\"float32\") / 255\nscaled_X_test_tiny_resized = X_test_tiny_resized.astype(\"float32\") / 255","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:12.806683Z","iopub.execute_input":"2022-05-15T18:46:12.807139Z","iopub.status.idle":"2022-05-15T18:46:13.531933Z","shell.execute_reply.started":"2022-05-15T18:46:12.807103Z","shell.execute_reply":"2022-05-15T18:46:13.531007Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_image_generator  = ImageDataGenerator(\n    rotation_range = 30,      # random rotation of the image. 40 degree\n    width_shift_range = 0.2,  # is the extent to which the image is panned horizontally or vertically\n    height_shift_range= 0.2,\n    shear_range= 0.2,         # the angle of the random staggered transformation.\n    zoom_range= 0.1,          # zoom in/zoom out\n    horizontal_flip= True,    # reverse\n    featurewise_center=True   # Color change\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:13.533518Z","iopub.execute_input":"2022-05-15T18:46:13.533814Z","iopub.status.idle":"2022-05-15T18:46:13.539449Z","shell.execute_reply.started":"2022-05-15T18:46:13.533777Z","shell.execute_reply":"2022-05-15T18:46:13.538399Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"scaled_X_test_small_resized.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:13.541279Z","iopub.execute_input":"2022-05-15T18:46:13.541680Z","iopub.status.idle":"2022-05-15T18:46:13.552521Z","shell.execute_reply.started":"2022-05-15T18:46:13.541632Z","shell.execute_reply":"2022-05-15T18:46:13.551139Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# We generate only train data for small and tiny\n\ntrain_small_generator = train_image_generator.flow(scaled_X_train_small_resized, y_train_small, batch_size=32)\ntest_small_generator = ImageDataGenerator()\nval_small_generator = test_small_generator.flow(scaled_X_val_small_resized, y_val_small, batch_size=32)\n\ntrain_tiny_generator = train_image_generator.flow(scaled_X_train_tiny_resized, y_train_tiny, batch_size=32)\ntest_tiny_generator = ImageDataGenerator()\nval_tiny_generator = test_tiny_generator.flow(scaled_X_val_tiny_resized, y_val_tiny, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:13.554203Z","iopub.execute_input":"2022-05-15T18:46:13.554502Z","iopub.status.idle":"2022-05-15T18:46:13.564996Z","shell.execute_reply.started":"2022-05-15T18:46:13.554455Z","shell.execute_reply":"2022-05-15T18:46:13.564208Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"For small data:","metadata":{}},{"cell_type":"code","source":"print(len(train_small_generator.next()))\n\nsample_batch = train_small_generator.next()\nprint(sample_batch[0].shape) # 32 samples in a batch\n\nplt.imshow(sample_batch[0][7])\nplt.suptitle(\"Sample of augmentation\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:13.568136Z","iopub.execute_input":"2022-05-15T18:46:13.568511Z","iopub.status.idle":"2022-05-15T18:46:14.783007Z","shell.execute_reply.started":"2022-05-15T18:46:13.568365Z","shell.execute_reply":"2022-05-15T18:46:14.781988Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# 2. Träna modeller (*)\n","metadata":{}},{"cell_type":"markdown","source":"#### För uppgifterna nedan, jobba med dataseten en åt gången:\n\nSmall\n\n- utan augmenterig \n- med augmentering\n\nTiny (BONUS)\n\n- utan augmentering\n- med augmentering","metadata":{}},{"cell_type":"markdown","source":"#### a) Använd följande nätverk och träna på datan. Gör hyperparametertuning för några parametrar (beskriv hur du gör). Visualisera och analysera loss-kurvor, accuracy-kurvor.","metadata":{}},{"cell_type":"markdown","source":"Create CNN model with layers:","metadata":{}},{"cell_type":"code","source":"def CNN_model(drop_rate, learning_rate):\n\n  model = models.Sequential() \n\n  adam = Adam(learning_rate=learning_rate)\n  \n  # Biuld Conv2D and MaxPooling2D layers:\n  # The depth of the feature map is increasing (from 32 to 128)\n  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3))) # same shape as we created\n  model.add(MaxPooling2D((2, 2)))\n  model.add(Conv2D(64, (3, 3), activation='relu')) \n  model.add(MaxPooling2D((2, 2))) \n  model.add(Conv2D(128, (3, 3), activation='relu')) \n  model.add(MaxPooling2D((2, 2))) \n  model.add(Conv2D(128, (3, 3), activation='relu')) \n  model.add(MaxPooling2D((2, 2)))\n\n  # connect to Flatten layer\n  model.add(Flatten())\n  model.add(Dropout(drop_rate)) # Dropout layer can reduce overfitting\n  model.add(Dense(512, activation='relu')) \n  model.add(Dense(1, activation='sigmoid'))\n\n  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n  # using binary crossentropy here because of sigmoid function (binary labels)\n\n  return model\n\n\nmodel = CNN_model(0.3, 0.001)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:14.789536Z","iopub.execute_input":"2022-05-15T18:46:14.790377Z","iopub.status.idle":"2022-05-15T18:46:17.617378Z","shell.execute_reply.started":"2022-05-15T18:46:14.790332Z","shell.execute_reply":"2022-05-15T18:46:17.615904Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"Create a function for plot:","metadata":{}},{"cell_type":"code","source":"def plot_metrics(metrics):\n    _, ax = plt.subplots(1,2, figsize = (12,4))\n    metrics[[\"loss\", \"val_loss\"]].plot(ax = ax[0], grid = True)\n    metrics[[\"acc\", \"val_acc\"]].plot(ax = ax[1], grid = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:17.620055Z","iopub.execute_input":"2022-05-15T18:46:17.620257Z","iopub.status.idle":"2022-05-15T18:46:17.628397Z","shell.execute_reply.started":"2022-05-15T18:46:17.620231Z","shell.execute_reply":"2022-05-15T18:46:17.627556Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"#### For tiny dataset without augmentation:","metadata":{}},{"cell_type":"code","source":"steps_per_epoch_tiny = int(len(scaled_X_train_tiny_resized)/32)\nvalidation_steps_tiny = int(len(scaled_X_val_tiny_resized)/32)\n\nsteps_per_epoch_tiny, validation_steps_tiny","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:17.630586Z","iopub.execute_input":"2022-05-15T18:46:17.630869Z","iopub.status.idle":"2022-05-15T18:46:17.638753Z","shell.execute_reply.started":"2022-05-15T18:46:17.630803Z","shell.execute_reply":"2022-05-15T18:46:17.637870Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# use ImageDataGenerator() for a non-augmentation dataset\n\ntest_tiny_generator_0 = ImageDataGenerator()\ntrain_tiny_generator_0 = test_tiny_generator_0.flow(scaled_X_train_tiny_resized, y_train_tiny, batch_size=32)\nval_tiny_generator_0 = test_tiny_generator_0.flow(scaled_X_val_tiny_resized, y_val_tiny, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:17.640414Z","iopub.execute_input":"2022-05-15T18:46:17.640746Z","iopub.status.idle":"2022-05-15T18:46:17.648166Z","shell.execute_reply.started":"2022-05-15T18:46:17.640709Z","shell.execute_reply":"2022-05-15T18:46:17.647316Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Here choose \"patience = 10, restore_best_weights = True, epochs = 50\"\nearly_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel.fit(\n    train_tiny_generator_0,\n    steps_per_epoch = steps_per_epoch_tiny,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_tiny_generator_0,\n    validation_steps = validation_steps_tiny\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:17.649504Z","iopub.execute_input":"2022-05-15T18:46:17.649834Z","iopub.status.idle":"2022-05-15T18:46:30.559664Z","shell.execute_reply.started":"2022-05-15T18:46:17.649785Z","shell.execute_reply":"2022-05-15T18:46:30.558934Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"metrics_tiny_without_augmentation = pd.DataFrame(model.history.history)\nplot_metrics(metrics_tiny_without_augmentation)\nplt.suptitle(\"Train/validation loss & Train/validation acc\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:30.563719Z","iopub.execute_input":"2022-05-15T18:46:30.565650Z","iopub.status.idle":"2022-05-15T18:46:31.201108Z","shell.execute_reply.started":"2022-05-15T18:46:30.565609Z","shell.execute_reply":"2022-05-15T18:46:31.200447Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"#### For tiny data with augmentation:","metadata":{}},{"cell_type":"code","source":"# Here choose \"patience = 10, restore_best_weights = True, epochs = 50\"\nearly_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel.fit(\n    train_tiny_generator,\n    steps_per_epoch = steps_per_epoch_tiny,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_tiny_generator,\n    validation_steps = validation_steps_tiny\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:46:31.205468Z","iopub.execute_input":"2022-05-15T18:46:31.207411Z","iopub.status.idle":"2022-05-15T18:47:27.758612Z","shell.execute_reply.started":"2022-05-15T18:46:31.207354Z","shell.execute_reply":"2022-05-15T18:47:27.757671Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"metrics_tiny = pd.DataFrame(model.history.history)\nplot_metrics(metrics_tiny)\nplt.suptitle(\"Train/validation loss & Train/validation acc\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:47:27.760189Z","iopub.execute_input":"2022-05-15T18:47:27.760568Z","iopub.status.idle":"2022-05-15T18:47:28.589791Z","shell.execute_reply.started":"2022-05-15T18:47:27.760521Z","shell.execute_reply":"2022-05-15T18:47:28.588805Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"#### For small dataset without augmentation","metadata":{}},{"cell_type":"code","source":"steps_per_epoch_small = int(len(scaled_X_train_small_resized)/32)\nvalidation_steps_small = int(len(scaled_X_val_small_resized)/32)\n\nsteps_per_epoch_small, validation_steps_small","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:47:28.591068Z","iopub.execute_input":"2022-05-15T18:47:28.591780Z","iopub.status.idle":"2022-05-15T18:47:28.600426Z","shell.execute_reply.started":"2022-05-15T18:47:28.591734Z","shell.execute_reply":"2022-05-15T18:47:28.599325Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"test_small_generator_0 = ImageDataGenerator()\ntrain_small_generator_0 = test_small_generator_0.flow(scaled_X_train_small_resized, y_train_small, batch_size=32)\nval_small_generator_0 = test_small_generator_0.flow(scaled_X_val_small_resized, y_val_small, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:47:28.602215Z","iopub.execute_input":"2022-05-15T18:47:28.602610Z","iopub.status.idle":"2022-05-15T18:47:28.611792Z","shell.execute_reply.started":"2022-05-15T18:47:28.602556Z","shell.execute_reply":"2022-05-15T18:47:28.610887Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# patience = 10, restore_best_weights = True\n\nearly_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel.fit(\n    train_small_generator_0,\n    steps_per_epoch = steps_per_epoch_small,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_small_generator_0,\n    validation_steps = validation_steps_small\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:47:28.613301Z","iopub.execute_input":"2022-05-15T18:47:28.613821Z","iopub.status.idle":"2022-05-15T18:48:10.214649Z","shell.execute_reply.started":"2022-05-15T18:47:28.613779Z","shell.execute_reply":"2022-05-15T18:48:10.213860Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"metrics_small_without_augmentation = pd.DataFrame(model.history.history)\nplot_metrics(metrics_small_without_augmentation)\nplt.suptitle(\"Train/validation loss & Train/validation acc\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:48:10.216891Z","iopub.execute_input":"2022-05-15T18:48:10.217310Z","iopub.status.idle":"2022-05-15T18:48:10.681261Z","shell.execute_reply.started":"2022-05-15T18:48:10.217272Z","shell.execute_reply":"2022-05-15T18:48:10.679870Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"The model fit well with train data but not with validation data.","metadata":{}},{"cell_type":"markdown","source":"#### For small dataset with augmentation","metadata":{}},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel.fit(\n    train_small_generator,\n    steps_per_epoch = steps_per_epoch_small,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_small_generator,\n    validation_steps = validation_steps_small\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T18:48:10.690912Z","iopub.execute_input":"2022-05-15T18:48:10.691710Z","iopub.status.idle":"2022-05-15T19:01:02.331606Z","shell.execute_reply.started":"2022-05-15T18:48:10.691601Z","shell.execute_reply":"2022-05-15T19:01:02.330879Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"metrics_small = pd.DataFrame(model.history.history)\nplot_metrics(metrics_small)\nplt.suptitle(\"Train/validation loss & Train/validation acc\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:01:02.332802Z","iopub.execute_input":"2022-05-15T19:01:02.333071Z","iopub.status.idle":"2022-05-15T19:01:02.915370Z","shell.execute_reply.started":"2022-05-15T19:01:02.333034Z","shell.execute_reply":"2022-05-15T19:01:02.914669Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"#### b) Förändra nätverket i a) experimentera och ändra i lite komponenter. Beskriv vad du ändrar och varför. Glöm inte att evaluera på valideringsdatan.\n","metadata":{}},{"cell_type":"markdown","source":"Model_2 try to use 3 Conv2D & MaxPooling 2D (64,128,128), drop_rate = 0.4, learning_rate = 0.002\n\nThe number of convolution kernels change to 64 on the first step. The reason for this is to set more information from the start.\n\nTry to increase the features in the beginning.","metadata":{}},{"cell_type":"code","source":"def CNN_model_2(drop_rate, learning_rate):\n\n  model = models.Sequential() \n\n  adam = Adam(learning_rate=learning_rate)\n  \n  # Biuld Conv2D and MaxPooling2D layers:\n  # The depth of the feature map is increasing (64, 128, 128)\n\n  model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n  model.add(MaxPooling2D((2, 2)))\n  model.add(Conv2D(128, (3, 3), activation='relu')) \n  model.add(MaxPooling2D((2, 2))) \n  model.add(Conv2D(128, (3, 3), activation='relu')) \n  model.add(MaxPooling2D((2, 2))) \n\n  model.add(Flatten())\n  model.add(Dropout(drop_rate))\n  model.add(Dense(512,activation='relu'))\n  model.add(Dense(1,activation='sigmoid'))\n  \n  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n  # using binary crossentropy here because of sigmoid function (binary labels)\n\n  return model\n\n\nmodel_2 = CNN_model_2(0.4, 0.002)\nmodel_2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:01:02.916525Z","iopub.execute_input":"2022-05-15T19:01:02.917991Z","iopub.status.idle":"2022-05-15T19:01:02.987659Z","shell.execute_reply.started":"2022-05-15T19:01:02.917950Z","shell.execute_reply":"2022-05-15T19:01:02.987013Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"***Model_2 for tiny data without augmentation:***","metadata":{}},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel_2.fit(\n    train_tiny_generator_0,\n    steps_per_epoch = steps_per_epoch_tiny,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_tiny_generator_0,\n    validation_steps = validation_steps_tiny\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:01:02.988762Z","iopub.execute_input":"2022-05-15T19:01:02.989057Z","iopub.status.idle":"2022-05-15T19:01:16.381434Z","shell.execute_reply.started":"2022-05-15T19:01:02.989016Z","shell.execute_reply":"2022-05-15T19:01:16.380763Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"metrics_tiny_2 = pd.DataFrame(model_2.history.history)\nplot_metrics(metrics_tiny_2)\nplt.suptitle(\"Train/validation loss & Train/validation acc for tiny model_2\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:01:16.385257Z","iopub.execute_input":"2022-05-15T19:01:16.387163Z","iopub.status.idle":"2022-05-15T19:01:17.279770Z","shell.execute_reply.started":"2022-05-15T19:01:16.387123Z","shell.execute_reply":"2022-05-15T19:01:17.279110Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"***Model_2 for tiny data with augmentation:***","metadata":{}},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel_2.fit(\n    train_tiny_generator,\n    steps_per_epoch = steps_per_epoch_tiny,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_tiny_generator,\n    validation_steps = validation_steps_tiny\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:01:17.280949Z","iopub.execute_input":"2022-05-15T19:01:17.281494Z","iopub.status.idle":"2022-05-15T19:02:05.744413Z","shell.execute_reply.started":"2022-05-15T19:01:17.281452Z","shell.execute_reply":"2022-05-15T19:02:05.743665Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"metrics_tiny_2 = pd.DataFrame(model_2.history.history)\nplot_metrics(metrics_tiny_2)\nplt.suptitle(\"Train/validation loss & Train/validation acc for tiny_aug model_2\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:02:05.745515Z","iopub.execute_input":"2022-05-15T19:02:05.746235Z","iopub.status.idle":"2022-05-15T19:02:06.123124Z","shell.execute_reply.started":"2022-05-15T19:02:05.746195Z","shell.execute_reply":"2022-05-15T19:02:06.122474Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"***Model_2 for Small data without augmentation:***","metadata":{}},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel_2.fit(\n    train_small_generator_0,\n    steps_per_epoch = steps_per_epoch_small,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_small_generator_0,\n    validation_steps = validation_steps_small\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:02:06.124228Z","iopub.execute_input":"2022-05-15T19:02:06.124483Z","iopub.status.idle":"2022-05-15T19:03:15.595866Z","shell.execute_reply.started":"2022-05-15T19:02:06.124441Z","shell.execute_reply":"2022-05-15T19:03:15.595201Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"metrics_small_2 = pd.DataFrame(model_2.history.history)\nplot_metrics(metrics_small_2)\nplt.suptitle(\"Train/validation loss & Train/validation acc for small model_2\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:03:15.597243Z","iopub.execute_input":"2022-05-15T19:03:15.597487Z","iopub.status.idle":"2022-05-15T19:03:16.112152Z","shell.execute_reply.started":"2022-05-15T19:03:15.597453Z","shell.execute_reply":"2022-05-15T19:03:16.111360Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"***Model_2 for Small data with augmentation:***","metadata":{}},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel_2.fit(\n    train_small_generator,\n    steps_per_epoch = steps_per_epoch_small,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_small_generator,\n    validation_steps = validation_steps_small\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:03:16.116218Z","iopub.execute_input":"2022-05-15T19:03:16.118204Z","iopub.status.idle":"2022-05-15T19:21:36.277425Z","shell.execute_reply.started":"2022-05-15T19:03:16.118164Z","shell.execute_reply":"2022-05-15T19:21:36.276680Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"metrics_small_2 = pd.DataFrame(model_2.history.history)\nplot_metrics(metrics_small_2)\nplt.suptitle(\"Train/validation loss & Train/validation acc for small_aug model_2\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:21:36.280398Z","iopub.execute_input":"2022-05-15T19:21:36.280600Z","iopub.status.idle":"2022-05-15T19:21:36.673952Z","shell.execute_reply.started":"2022-05-15T19:21:36.280574Z","shell.execute_reply":"2022-05-15T19:21:36.673291Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"Model_3 try to use 4 Conv2D & MaxPooling 2D (64,128,128,256), drop_rate = 0.5, learning_rate = 0.001\n\nThe number of convolution kernels change to 32 in the first step and add a 256 kernel. I try to add more information at the end of filtering.","metadata":{}},{"cell_type":"code","source":"def CNN_model_3(drop_rate, learning_rate):\n\n  model = models.Sequential() \n\n  adam = Adam(learning_rate=learning_rate)\n  \n  # Biuld Conv2D and MaxPooling2D layers:\n  # The depth of the feature map is increasing (32, 64, 128, 128, 256)\n\n  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n  model.add(MaxPooling2D((2, 2)))\n  model.add(Conv2D(64, (3, 3), activation='relu'))\n  model.add(MaxPooling2D((2, 2)))\n  model.add(Conv2D(128, (3, 3), activation='relu')) \n  model.add(MaxPooling2D((2, 2))) \n  model.add(Conv2D(128, (3, 3), activation='relu')) \n  model.add(MaxPooling2D((2, 2)))\n  model.add(Conv2D(256, (3, 3), activation='relu')) \n  model.add(MaxPooling2D((2, 2)))\n\n  model.add(Flatten())\n  model.add(Dropout(drop_rate))\n  model.add(Dense(512,activation='relu'))\n  model.add(Dense(1,activation='sigmoid'))\n  \n  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n  # using binary crossentropy here because of sigmoid function (binary labels)\n\n  return model\n\n\nmodel_3 = CNN_model_3(0.5, 0.001)\nmodel_3.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:21:36.675150Z","iopub.execute_input":"2022-05-15T19:21:36.675468Z","iopub.status.idle":"2022-05-15T19:21:36.770811Z","shell.execute_reply.started":"2022-05-15T19:21:36.675428Z","shell.execute_reply":"2022-05-15T19:21:36.770123Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"***Model_3 for tiny data without augmentation:***","metadata":{}},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel_3.fit(\n    train_tiny_generator_0,\n    steps_per_epoch = steps_per_epoch_tiny,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_tiny_generator_0,\n    validation_steps = validation_steps_tiny\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:21:36.772055Z","iopub.execute_input":"2022-05-15T19:21:36.772321Z","iopub.status.idle":"2022-05-15T19:21:46.186808Z","shell.execute_reply.started":"2022-05-15T19:21:36.772285Z","shell.execute_reply":"2022-05-15T19:21:46.186155Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"metrics_tiny_3 = pd.DataFrame(model_3.history.history)\nplot_metrics(metrics_tiny_3)\nplt.suptitle(\"Train/validation loss & Train/validation acc for tiny model_3\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:21:46.188242Z","iopub.execute_input":"2022-05-15T19:21:46.188489Z","iopub.status.idle":"2022-05-15T19:21:46.857737Z","shell.execute_reply.started":"2022-05-15T19:21:46.188454Z","shell.execute_reply":"2022-05-15T19:21:46.857005Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"***Model_3 for tiny data with augmentation:***","metadata":{}},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel_3.fit(\n    train_tiny_generator,\n    steps_per_epoch = steps_per_epoch_tiny,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_tiny_generator,\n    validation_steps = validation_steps_tiny\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:21:46.858943Z","iopub.execute_input":"2022-05-15T19:21:46.859590Z","iopub.status.idle":"2022-05-15T19:22:11.501592Z","shell.execute_reply.started":"2022-05-15T19:21:46.859543Z","shell.execute_reply":"2022-05-15T19:22:11.500713Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"metrics_tiny_3 = pd.DataFrame(model_3.history.history)\nplot_metrics(metrics_tiny_3)\nplt.suptitle(\"Train/validation loss & Train/validation acc for tiny_aug model_3\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:22:11.502983Z","iopub.execute_input":"2022-05-15T19:22:11.503260Z","iopub.status.idle":"2022-05-15T19:22:11.887709Z","shell.execute_reply.started":"2022-05-15T19:22:11.503223Z","shell.execute_reply":"2022-05-15T19:22:11.887058Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"***Model_3 for small data without augmentation:***","metadata":{}},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel_3.fit(\n    train_small_generator_0,\n    steps_per_epoch = steps_per_epoch_small,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_small_generator_0,\n    validation_steps = validation_steps_small\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:22:11.889108Z","iopub.execute_input":"2022-05-15T19:22:11.889364Z","iopub.status.idle":"2022-05-15T19:23:15.480428Z","shell.execute_reply.started":"2022-05-15T19:22:11.889329Z","shell.execute_reply":"2022-05-15T19:23:15.479635Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"metrics_small_3 = pd.DataFrame(model_3.history.history)\nplot_metrics(metrics_small_3)\nplt.suptitle(\"Train/validation loss & Train/validation acc for small model_3\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:23:15.484979Z","iopub.execute_input":"2022-05-15T19:23:15.485646Z","iopub.status.idle":"2022-05-15T19:23:18.245933Z","shell.execute_reply.started":"2022-05-15T19:23:15.485601Z","shell.execute_reply":"2022-05-15T19:23:18.245266Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"***Model_3 for small data with augmentation:***","metadata":{}},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel_3.fit(\n    train_small_generator,\n    steps_per_epoch = steps_per_epoch_small,\n    epochs = 50,\n    callbacks = [early_stopper],\n    validation_data = val_small_generator,\n    validation_steps = validation_steps_small\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:23:18.247676Z","iopub.execute_input":"2022-05-15T19:23:18.248529Z","iopub.status.idle":"2022-05-15T19:34:07.660608Z","shell.execute_reply.started":"2022-05-15T19:23:18.248489Z","shell.execute_reply":"2022-05-15T19:34:07.659803Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"metrics_small_3 = pd.DataFrame(model_3.history.history)\nplot_metrics(metrics_small_3)\nplt.suptitle(\"Train/validation loss & Train/validation acc for small_aug model_3\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:34:07.661930Z","iopub.execute_input":"2022-05-15T19:34:07.662209Z","iopub.status.idle":"2022-05-15T19:34:08.085557Z","shell.execute_reply.started":"2022-05-15T19:34:07.662169Z","shell.execute_reply":"2022-05-15T19:34:08.084698Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"**Summary**:\n\n- Model_1: One layer removed(32 features) does not have much effect on the model. The drop rate is increased to 0.4 and the learning rate is increased to 0.002\n- Model_2: When adding a layer (256 features), the model is greatly improved. The increase in accuracy is significant. The drop rate is increased to 0.5 and the learning rate is restored to 0.001\n- The step and the input_shape were not changed. Only the effect of layers on models is compaired here.\n- Note that the small data perform better than tiny data on both models with Aug/non-aug, because of the data size is limit.\n- The accuracy or loss of training on original data can be higher than the accuracy or loss on augmentation data, but on the validation data, augmentayion perform better than original data on both models. The stability and fitness of augmentation data are better.","metadata":{}},{"cell_type":"markdown","source":"#### c) Välj en modell, träna på tränings- och valideringsdatan. Gör inferens på testdatan och utvärdera din modell.\n","metadata":{}},{"cell_type":"markdown","source":"Model_3 will be choosen","metadata":{}},{"cell_type":"code","source":"# Concatenate the training and validation data\n\nX_train_val_small = np.concatenate((scaled_X_train_small_resized, scaled_X_val_small_resized))\ny_train_val_small = np.concatenate((y_train_small, y_val_small))\nX_train_val_small.shape, y_train_val_small.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:34:08.087051Z","iopub.execute_input":"2022-05-15T19:34:08.087391Z","iopub.status.idle":"2022-05-15T19:34:09.103467Z","shell.execute_reply.started":"2022-05-15T19:34:08.087349Z","shell.execute_reply":"2022-05-15T19:34:09.102738Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"train_val_small_generator = train_image_generator.flow(X_train_val_small, y_train_val_small, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:34:09.104632Z","iopub.execute_input":"2022-05-15T19:34:09.104904Z","iopub.status.idle":"2022-05-15T19:34:09.110298Z","shell.execute_reply.started":"2022-05-15T19:34:09.104863Z","shell.execute_reply":"2022-05-15T19:34:09.109450Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"early_stopper = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 10, restore_best_weights = True)\n\nmodel_3.fit(\n    train_val_small_generator,\n    steps_per_epoch = steps_per_epoch_small,\n    epochs = 50,\n    callbacks = [early_stopper]\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T19:34:09.111563Z","iopub.execute_input":"2022-05-15T19:34:09.112338Z","iopub.status.idle":"2022-05-15T20:02:03.039277Z","shell.execute_reply.started":"2022-05-15T19:34:09.112292Z","shell.execute_reply":"2022-05-15T20:02:03.038578Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"#### *Valuation*","metadata":{}},{"cell_type":"code","source":"y_pred_small_3 = model_3.predict(scaled_X_test_small_resized)\ny_pred_small_3 = ((y_pred_small_3 > 0.5)+0).ravel() # transfer probabilities to 0/1\ny_test_small = np.array(y_test_small)\n\nprint(classification_report(y_test_small, y_pred_small_3))\ncm = confusion_matrix(y_test_small, y_pred_small_3)\nConfusionMatrixDisplay(cm).plot()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T20:02:03.042466Z","iopub.execute_input":"2022-05-15T20:02:03.045280Z","iopub.status.idle":"2022-05-15T20:02:04.634548Z","shell.execute_reply.started":"2022-05-15T20:02:03.045238Z","shell.execute_reply":"2022-05-15T20:02:04.633715Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"*Accuracy reach to about 90%, extremely good!*","metadata":{}},{"cell_type":"markdown","source":"Prediction test with my image","metadata":{}},{"cell_type":"code","source":"huihui = plt.imread(\"../input/huihui/huihui.jpg\")\nplt.imshow(huihui)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T20:36:27.689158Z","iopub.execute_input":"2022-05-15T20:36:27.689694Z","iopub.status.idle":"2022-05-15T20:36:27.934516Z","shell.execute_reply.started":"2022-05-15T20:36:27.689634Z","shell.execute_reply":"2022-05-15T20:36:27.933839Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"huihui = cv2.resize(huihui, (256, 256))\nhuihui_scaled = huihui.astype(\"float32\") / 255\nhuihui_scaled = huihui_scaled[None,:,:,:] # add a dimension\nhuihui_scaled.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-15T20:36:31.593488Z","iopub.execute_input":"2022-05-15T20:36:31.594012Z","iopub.status.idle":"2022-05-15T20:36:31.602130Z","shell.execute_reply.started":"2022-05-15T20:36:31.593974Z","shell.execute_reply":"2022-05-15T20:36:31.601211Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"huihui_p = model_3.predict(huihui_scaled)\nhuihui_p = ((huihui_p > 0.5)+0).ravel()\nhuihui_p","metadata":{"execution":{"iopub.status.busy":"2022-05-15T20:36:57.865701Z","iopub.execute_input":"2022-05-15T20:36:57.866275Z","iopub.status.idle":"2022-05-15T20:36:57.913733Z","shell.execute_reply.started":"2022-05-15T20:36:57.866235Z","shell.execute_reply":"2022-05-15T20:36:57.913043Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"#### d) Tag ett eller flera av nätverken (VGG16, Resnet, Xception, Inception), läs deras forskningsartikel, sammanfatta kort ca 1/2 - 1 sida för en artikel. Utför därefter transfer learning och evaluera din modell. Beskriv också hur transfer learning fungerar.\n","metadata":{}},{"cell_type":"markdown","source":"##### VGG16 summary:","metadata":{}},{"cell_type":"markdown","source":"- VGG16 is a model proposed by the Visual Geometry Group of Oxford University.\n- VGG16 is characterized by proving that small convolutions can effectively improve performance by increasing the network depth.\n- The default size of VGG16 for input images is 224 * 224 * 3. The VGG16 network structure has a total of 16 layers (with parameters), that is, 13 convolutional layers, 5 pooling layers(without parameters), and 3 fully connected layers, excluding the activation function(layers)\n- conv3-64 means that the dimension becomes 64 after the third layer of convolution. Similarly, conv3-128 means that the dimension becomes 128 after the third layer of convolution\n- FC-4096 refers to 4096 nodes in the fully connected layer, FC-1000 is a fully connected layer with 1000 nodes","metadata":{}},{"cell_type":"markdown","source":"|             Modules         | The layers of each module |\n|-----------------------------|---------------------------|\n|                Input images |             224 * 224 * 3     |\n| | |\n|||\n|                 Module_1    |               **conv3-64**|\n|                             |               **conv3-64**    |\n|                             |               maxpool     |\n|                 Module_2    |               **conv3-128**   |\n|                             |               **conv3-128**   |\n|                             |               maxpool     |\n|                 Module_3    |               **conv3-256**   |\n|                             |               **conv3-256**   |\n|                             |               **conv3-256**   |\n|                             |               maxpool     |\n|                 Module_4    |               **conv3-512**   |\n|                             |               **conv3-512**   |\n|                             |               **conv3-512**   |\n|                             |               maxpool     |\n|                 Module_5    |               **conv3-512**   |\n|                             |               **conv3-512**   |\n|                             |               **conv3-512**   |\n|                             |               maxpool     |\n|      Module_6 (full connection layer and output layer)           |          (Flatten)         |\n|                |          **FC-4096**          |\n|                |          **FC-4096**          |\n|                |          **FC-1000**  (classification)        |\n|                |          softmax (Output function)          |","metadata":{}},{"cell_type":"markdown","source":"Process: 224 * 224 * 3 input: \n- conv1_1+conv1_2+pool_1：1st conv1, (3 * 3 * 3) * 64 = 1728(training parameters) --- 2st conv1（3 * 3 * 64） * 64=36864(training parameters); after maxpool(2 * 2), size: 112 * 112 * 64\n- conv2_1+conv2_2+pool_2：after 2st conv2,（3 * 3 * 128） * 128=147456(training parameters); after maxpool, size: 56 * 56 * 128\n- conv3_1+conv3_2+conv3_3+pool_3：after 3st conv3,（3 * 3 * 256） * 256=589824(training parameters); after maxpool, size: 28 * 28 * 256\n- conv4_1+conv4_2+conv4_3+pool_4：after 3st conv4,（3 * 3 * 512） * 512=2359296(training parameters); after maxpool, size: 14 * 14 * 512\n- conv5_1+conv5_2+conv5_3+pool_5：after 3st conv5,（3 * 3 * 512） * 512=2359296(training parameters); after maxpool, size: 7 * 7 * 512","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\n\ninput_shape = 256, 256, 3\n\nbase_model = VGG16(weights=\"imagenet\", include_top=False,\n                   input_shape=(input_shape))\n\nbase_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T20:37:26.213624Z","iopub.execute_input":"2022-05-15T20:37:26.213903Z","iopub.status.idle":"2022-05-15T20:37:26.912139Z","shell.execute_reply.started":"2022-05-15T20:37:26.213872Z","shell.execute_reply":"2022-05-15T20:37:26.911244Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"model_transfer = Sequential([\n    base_model,\n    Flatten(),\n    Dropout(.5),\n    Dense(256, activation=\"relu\", kernel_initializer=\"he_normal\"),\n    Dropout(.5),\n    Dense(1, activation=\"sigmoid\")\n], name = \"Transfer_model\")\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel_transfer.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"acc\"])\n\nmodel_transfer.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T20:37:30.571890Z","iopub.execute_input":"2022-05-15T20:37:30.572170Z","iopub.status.idle":"2022-05-15T20:37:30.664213Z","shell.execute_reply.started":"2022-05-15T20:37:30.572140Z","shell.execute_reply":"2022-05-15T20:37:30.663370Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"Here applying relevant parts of a pre-trained machine learning model(VGG16) to our problem. Which \"base_model\" is the core information (operation) of the model, and new layers(flatten,dropout,denses) are added to the model to our cats/dogs tasks.","metadata":{}},{"cell_type":"code","source":"model_transfer.fit(train_tiny_generator_0, epochs = 20, validation_data = val_tiny_generator_0)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T20:37:34.950121Z","iopub.execute_input":"2022-05-15T20:37:34.950388Z","iopub.status.idle":"2022-05-15T20:37:52.904389Z","shell.execute_reply.started":"2022-05-15T20:37:34.950359Z","shell.execute_reply":"2022-05-15T20:37:52.903681Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"metrics = pd.DataFrame(model_transfer.history.history)\nmetrics.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T20:38:09.673686Z","iopub.execute_input":"2022-05-15T20:38:09.674201Z","iopub.status.idle":"2022-05-15T20:38:09.688574Z","shell.execute_reply.started":"2022-05-15T20:38:09.674163Z","shell.execute_reply":"2022-05-15T20:38:09.687541Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"metrics[[\"acc\", \"val_acc\"]].plot()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T20:37:58.227915Z","iopub.execute_input":"2022-05-15T20:37:58.229004Z","iopub.status.idle":"2022-05-15T20:37:58.455254Z","shell.execute_reply.started":"2022-05-15T20:37:58.228944Z","shell.execute_reply":"2022-05-15T20:37:58.454579Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"References: \n- https://www.kaggle.com/code/rkb0023/cnn-classifier-cats-and-dogs\n- https://www.kaggle.com/code/utshabkumarghosh/dogvcat2/notebook\n- https://www.kaggle.com/code/akshat4112/cats-vs-dogs-using-convnets-transfer-learning\n- https://arxiv.org/pdf/1409.1556.pdf\n- https://blog.csdn.net/hgnuxc_1993/article/details/115956774?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165238847816781483760778%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=165238847816781483760778&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-115956774-null-null.142^v9^pc_search_result_control_group,157^v4^control&utm_term=vgg16%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3&spm=1018.2226.3001.4187","metadata":{}}]}